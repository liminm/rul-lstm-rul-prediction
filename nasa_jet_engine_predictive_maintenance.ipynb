{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3042b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Create a directory for the data\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# 2. Download the zip file (using a reliable mirror for the NASA dataset)\n",
    "!#wget https://data.nasa.gov/docs/legacy/CMAPSSData.zip -O data/CMAPSSData.zip\n",
    "\n",
    "# 3. Unzip it\n",
    "#!unzip -o data/CMAPSSData.zip -d data/\n",
    "\n",
    "#print(\"Data downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f630136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_nr', 'time_cycles', 'setting_1', 'setting_2', 'setting_3', 's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n"
     ]
    }
   ],
   "source": [
    "# The dataset has 26 columns\n",
    "# 1. Unit Number (Which engine is it?)\n",
    "# 2. Time Cycles (How long has it been running?)\n",
    "# 3-5. Operational Settings (Altitude, Speed, etc.)\n",
    "# 6-26. Sensor Readings (s1 to s21)\n",
    "\n",
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1, 22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b813980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (20631, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1        1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2        1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3        1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4        1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "       s_3      s_4    s_5  ...    s_12     s_13     s_14    s_15  s_16  s_17  \\\n",
       "0  1589.70  1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392   \n",
       "1  1591.82  1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392   \n",
       "2  1587.99  1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390   \n",
       "3  1582.79  1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392   \n",
       "4  1582.85  1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393   \n",
       "\n",
       "   s_18   s_19   s_20     s_21  \n",
       "0  2388  100.0  39.06  23.4190  \n",
       "1  2388  100.0  39.00  23.4236  \n",
       "2  2388  100.0  38.95  23.3442  \n",
       "3  2388  100.0  38.88  23.3739  \n",
       "4  2388  100.0  38.90  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('data/train_FD001.txt', sep=r'\\s+', header=None, names=col_names)\n",
    "\n",
    "print(\"Training data shape:\", data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "32b72619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unit_nr',\n",
       " 'time_cycles',\n",
       " 'setting_1',\n",
       " 'setting_2',\n",
       " 'setting_3',\n",
       " 's_1',\n",
       " 's_2',\n",
       " 's_3',\n",
       " 's_4',\n",
       " 's_5',\n",
       " 's_6',\n",
       " 's_7',\n",
       " 's_8',\n",
       " 's_9',\n",
       " 's_10',\n",
       " 's_11',\n",
       " 's_12',\n",
       " 's_13',\n",
       " 's_14',\n",
       " 's_15',\n",
       " 's_16',\n",
       " 's_17',\n",
       " 's_18',\n",
       " 's_19',\n",
       " 's_20',\n",
       " 's_21']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8cdbbbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_nr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         max_cycle\n",
       "unit_nr           \n",
       "1              192\n",
       "2              287\n",
       "3              179\n",
       "4              189\n",
       "5              269"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value_cycle = data_df.groupby('unit_nr')['time_cycles'].max()\n",
    "\n",
    "# Convert Series to DataFrame with a specific column name\n",
    "max_cycle_df = max_value_cycle.to_frame(name='max_cycle')\n",
    "max_cycle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d882b36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "88acc30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1        1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2        1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3        1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4        1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "       s_3      s_4    s_5  ...     s_13     s_14    s_15  s_16  s_17  s_18  \\\n",
       "0  1589.70  1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03   392  2388   \n",
       "1  1591.82  1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03   392  2388   \n",
       "2  1587.99  1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03   390  2388   \n",
       "3  1582.79  1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03   392  2388   \n",
       "4  1582.85  1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03   393  2388   \n",
       "\n",
       "    s_19   s_20     s_21  max_cycle  \n",
       "0  100.0  39.06  23.4190        192  \n",
       "1  100.0  39.00  23.4236        192  \n",
       "2  100.0  38.95  23.3442        192  \n",
       "3  100.0  38.88  23.3739        192  \n",
       "4  100.0  38.90  23.4044        192  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.merge(max_cycle_df, left_on='unit_nr', right_index=True)\n",
    "data_df.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fb177989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>max_cycle</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>192</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>192</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>192</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1        1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2        1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3        1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4        1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "       s_3      s_4    s_5  ...     s_14    s_15  s_16  s_17  s_18   s_19  \\\n",
       "0  1589.70  1400.60  14.62  ...  8138.62  8.4195  0.03   392  2388  100.0   \n",
       "1  1591.82  1403.14  14.62  ...  8131.49  8.4318  0.03   392  2388  100.0   \n",
       "2  1587.99  1404.20  14.62  ...  8133.23  8.4178  0.03   390  2388  100.0   \n",
       "3  1582.79  1401.87  14.62  ...  8133.83  8.3682  0.03   392  2388  100.0   \n",
       "4  1582.85  1406.22  14.62  ...  8133.80  8.4294  0.03   393  2388  100.0   \n",
       "\n",
       "    s_20     s_21  max_cycle  RUL  \n",
       "0  39.06  23.4190        192  191  \n",
       "1  39.00  23.4236        192  190  \n",
       "2  38.95  23.3442        192  189  \n",
       "3  38.88  23.3739        192  188  \n",
       "4  38.90  23.4044        192  187  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['RUL'] = (\n",
    "    data_df['max_cycle'] - data_df['time_cycles']\n",
    ")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "17b337b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20631 entries, 0 to 20630\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   unit_nr      20631 non-null  int64  \n",
      " 1   time_cycles  20631 non-null  int64  \n",
      " 2   setting_1    20631 non-null  float64\n",
      " 3   setting_2    20631 non-null  float64\n",
      " 4   setting_3    20631 non-null  float64\n",
      " 5   s_1          20631 non-null  float64\n",
      " 6   s_2          20631 non-null  float64\n",
      " 7   s_3          20631 non-null  float64\n",
      " 8   s_4          20631 non-null  float64\n",
      " 9   s_5          20631 non-null  float64\n",
      " 10  s_6          20631 non-null  float64\n",
      " 11  s_7          20631 non-null  float64\n",
      " 12  s_8          20631 non-null  float64\n",
      " 13  s_9          20631 non-null  float64\n",
      " 14  s_10         20631 non-null  float64\n",
      " 15  s_11         20631 non-null  float64\n",
      " 16  s_12         20631 non-null  float64\n",
      " 17  s_13         20631 non-null  float64\n",
      " 18  s_14         20631 non-null  float64\n",
      " 19  s_15         20631 non-null  float64\n",
      " 20  s_16         20631 non-null  float64\n",
      " 21  s_17         20631 non-null  int64  \n",
      " 22  s_18         20631 non-null  int64  \n",
      " 23  s_19         20631 non-null  float64\n",
      " 24  s_20         20631 non-null  float64\n",
      " 25  s_21         20631 non-null  float64\n",
      " 26  max_cycle    20631 non-null  int64  \n",
      " 27  RUL          20631 non-null  int64  \n",
      "dtypes: float64(22), int64(6)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717acc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.68</td>\n",
       "      <td>1584.15</td>\n",
       "      <td>1396.08</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.49</td>\n",
       "      <td>2387.93</td>\n",
       "      <td>8140.44</td>\n",
       "      <td>8.4018</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>23.5027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.73</td>\n",
       "      <td>1579.03</td>\n",
       "      <td>1402.52</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.27</td>\n",
       "      <td>2387.94</td>\n",
       "      <td>8136.67</td>\n",
       "      <td>8.3867</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.18</td>\n",
       "      <td>23.4234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.30</td>\n",
       "      <td>1577.50</td>\n",
       "      <td>1396.76</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.80</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8133.65</td>\n",
       "      <td>8.3800</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.15</td>\n",
       "      <td>23.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.03</td>\n",
       "      <td>1587.49</td>\n",
       "      <td>1400.65</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.14</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8136.33</td>\n",
       "      <td>8.3941</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>23.4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.55</td>\n",
       "      <td>1590.41</td>\n",
       "      <td>1395.39</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.77</td>\n",
       "      <td>2387.96</td>\n",
       "      <td>8137.92</td>\n",
       "      <td>8.3861</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.11</td>\n",
       "      <td>23.4381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0          1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1          1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2          1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3          1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4          1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "..       ...          ...        ...        ...        ...     ...     ...   \n",
       "195        2            4     0.0035    -0.0004      100.0  518.67  641.68   \n",
       "196        2            5     0.0005     0.0004      100.0  518.67  641.73   \n",
       "197        2            6    -0.0010     0.0004      100.0  518.67  641.30   \n",
       "198        2            7     0.0001    -0.0002      100.0  518.67  642.03   \n",
       "199        2            8     0.0015    -0.0004      100.0  518.67  642.55   \n",
       "\n",
       "         s_3      s_4    s_5  ...    s_12     s_13     s_14    s_15  s_16  \\\n",
       "0    1589.70  1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   \n",
       "1    1591.82  1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   \n",
       "2    1587.99  1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   \n",
       "3    1582.79  1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   \n",
       "4    1582.85  1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   \n",
       "..       ...      ...    ...  ...     ...      ...      ...     ...   ...   \n",
       "195  1584.15  1396.08  14.62  ...  522.49  2387.93  8140.44  8.4018  0.03   \n",
       "196  1579.03  1402.52  14.62  ...  522.27  2387.94  8136.67  8.3867  0.03   \n",
       "197  1577.50  1396.76  14.62  ...  522.80  2387.99  8133.65  8.3800  0.03   \n",
       "198  1587.49  1400.65  14.62  ...  522.14  2388.04  8136.33  8.3941  0.03   \n",
       "199  1590.41  1395.39  14.62  ...  522.77  2387.96  8137.92  8.3861  0.03   \n",
       "\n",
       "     s_17  s_18   s_19   s_20     s_21  \n",
       "0     392  2388  100.0  39.06  23.4190  \n",
       "1     392  2388  100.0  39.00  23.4236  \n",
       "2     390  2388  100.0  38.95  23.3442  \n",
       "3     392  2388  100.0  38.88  23.3739  \n",
       "4     393  2388  100.0  38.90  23.4044  \n",
       "..    ...   ...    ...    ...      ...  \n",
       "195   391  2388  100.0  39.13  23.5027  \n",
       "196   390  2388  100.0  39.18  23.4234  \n",
       "197   392  2388  100.0  39.15  23.4270  \n",
       "198   391  2388  100.0  39.10  23.4718  \n",
       "199   391  2388  100.0  39.11  23.4381  \n",
       "\n",
       "[200 rows x 26 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df = data_df[setting_names].copy()\n",
    "#train_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089539bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20631 entries, 0 to 20630\n",
      "Data columns (total 26 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   unit_nr      20631 non-null  int64  \n",
      " 1   time_cycles  20631 non-null  int64  \n",
      " 2   setting_1    20631 non-null  float64\n",
      " 3   setting_2    20631 non-null  float64\n",
      " 4   setting_3    20631 non-null  float64\n",
      " 5   s_1          20631 non-null  float64\n",
      " 6   s_2          20631 non-null  float64\n",
      " 7   s_3          20631 non-null  float64\n",
      " 8   s_4          20631 non-null  float64\n",
      " 9   s_5          20631 non-null  float64\n",
      " 10  s_6          20631 non-null  float64\n",
      " 11  s_7          20631 non-null  float64\n",
      " 12  s_8          20631 non-null  float64\n",
      " 13  s_9          20631 non-null  float64\n",
      " 14  s_10         20631 non-null  float64\n",
      " 15  s_11         20631 non-null  float64\n",
      " 16  s_12         20631 non-null  float64\n",
      " 17  s_13         20631 non-null  float64\n",
      " 18  s_14         20631 non-null  float64\n",
      " 19  s_15         20631 non-null  float64\n",
      " 20  s_16         20631 non-null  float64\n",
      " 21  s_17         20631 non-null  int64  \n",
      " 22  s_18         20631 non-null  int64  \n",
      " 23  s_19         20631 non-null  float64\n",
      " 24  s_20         20631 non-null  float64\n",
      " 25  s_21         20631 non-null  float64\n",
      "dtypes: float64(22), int64(4)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d4357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale: ['time_cycles', 'setting_1', 'setting_2', 'setting_3', 's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "0        1      0.00000   0.459770   0.166667        0.0  0.0  0.183735   \n",
       "1        1      0.00277   0.609195   0.250000        0.0  0.0  0.283133   \n",
       "2        1      0.00554   0.252874   0.750000        0.0  0.0  0.343373   \n",
       "3        1      0.00831   0.540230   0.500000        0.0  0.0  0.343373   \n",
       "4        1      0.01108   0.390805   0.333333        0.0  0.0  0.349398   \n",
       "\n",
       "        s_3       s_4  s_5  ...      s_14      s_15  s_16      s_17  s_18  \\\n",
       "0  0.406802  0.309757  0.0  ...  0.199608  0.363986   0.0  0.333333   0.0   \n",
       "1  0.453019  0.352633  0.0  ...  0.162813  0.411312   0.0  0.333333   0.0   \n",
       "2  0.369523  0.370527  0.0  ...  0.171793  0.357445   0.0  0.166667   0.0   \n",
       "3  0.256159  0.331195  0.0  ...  0.174889  0.166603   0.0  0.333333   0.0   \n",
       "4  0.257467  0.404625  0.0  ...  0.174734  0.402078   0.0  0.416667   0.0   \n",
       "\n",
       "   s_19      s_20      s_21  RUL  max_cycle  \n",
       "0   0.0  0.713178  0.724662  191        192  \n",
       "1   0.0  0.666667  0.731014  190        192  \n",
       "2   0.0  0.627907  0.621375  189        192  \n",
       "3   0.0  0.573643  0.662386  188        192  \n",
       "4   0.0  0.589147  0.704502  187        192  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "not_scaled_cols = ['unit_nr', 'RUL', 'max_cycle']\n",
    "\n",
    "col_set = set(col_names)\n",
    "columns_to_scale = [col for col in col_names if col not in not_scaled_cols]\n",
    "\n",
    "print(\"Columns to scale:\", columns_to_scale)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(data_df[columns_to_scale])\n",
    "scaled_data_df = pd.DataFrame(scaled, columns=columns_to_scale, index=data_df.index)\n",
    "\n",
    "scaled_data_df.insert(0, 'unit_nr', data_df['unit_nr'])\n",
    "scaled_data_df.insert(len(scaled_data_df.columns), 'RUL', data_df['RUL'])\n",
    "scaled_data_df.insert(len(scaled_data_df.columns), 'max_cycle', data_df['max_cycle'])\n",
    "scaled_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a30bb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_scaled = pd.DataFrame(scaled_features, columns=columns_to_scale)\n",
    "#train_df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d24c77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequence_length = 50\n",
    "\n",
    "def create_sequences(data, targets, seq_length=50):\n",
    "    sequences = []\n",
    "    target_list = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        seq = data[i:i + seq_length]\n",
    "        target = targets[i + seq_length - 1]\n",
    "        sequences.append(seq)\n",
    "        target_list.append(target)\n",
    "    return np.array(sequences), np.array(target_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ff68924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_ids = scaled_data_df['unit_nr'].unique()\n",
    "engine_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7cd502a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train ids: 80\n",
      "len test ids: 20\n",
      "len engine ids: 100\n"
     ]
    }
   ],
   "source": [
    "train_ids = engine_ids[:80]\n",
    "test_ids = engine_ids[80:]\n",
    "print(\"len train ids:\", len(train_ids))\n",
    "print(\"len test ids:\", len(test_ids))\n",
    "print(\"len engine ids:\", len(engine_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "0        1      0.00000   0.459770   0.166667        0.0  0.0  0.183735   \n",
       "1        1      0.00277   0.609195   0.250000        0.0  0.0  0.283133   \n",
       "2        1      0.00554   0.252874   0.750000        0.0  0.0  0.343373   \n",
       "3        1      0.00831   0.540230   0.500000        0.0  0.0  0.343373   \n",
       "4        1      0.01108   0.390805   0.333333        0.0  0.0  0.349398   \n",
       "\n",
       "        s_3       s_4  s_5  ...      s_12      s_13      s_14      s_15  s_16  \\\n",
       "0  0.406802  0.309757  0.0  ...  0.633262  0.205882  0.199608  0.363986   0.0   \n",
       "1  0.453019  0.352633  0.0  ...  0.765458  0.279412  0.162813  0.411312   0.0   \n",
       "2  0.369523  0.370527  0.0  ...  0.795309  0.220588  0.171793  0.357445   0.0   \n",
       "3  0.256159  0.331195  0.0  ...  0.889126  0.294118  0.174889  0.166603   0.0   \n",
       "4  0.257467  0.404625  0.0  ...  0.746269  0.235294  0.174734  0.402078   0.0   \n",
       "\n",
       "       s_17  s_18  s_19      s_20      s_21  \n",
       "0  0.333333   0.0   0.0  0.713178  0.724662  \n",
       "1  0.333333   0.0   0.0  0.666667  0.731014  \n",
       "2  0.166667   0.0   0.0  0.627907  0.621375  \n",
       "3  0.333333   0.0   0.0  0.573643  0.662386  \n",
       "4  0.416667   0.0   0.0  0.589147  0.704502  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unit_id = engine_ids[0]\n",
    "#subset = scaled_data_df[scaled_data_df['unit_nr'] == unit_id]\n",
    "#print(subset.shape)\n",
    "#subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "37d90152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unit id: 1 with shape: (192, 26) and targets shape: (192,)\n",
      "Processing unit id: 2 with shape: (287, 26) and targets shape: (287,)\n",
      "Processing unit id: 3 with shape: (179, 26) and targets shape: (179,)\n",
      "Processing unit id: 4 with shape: (189, 26) and targets shape: (189,)\n",
      "Processing unit id: 5 with shape: (269, 26) and targets shape: (269,)\n",
      "Processing unit id: 6 with shape: (188, 26) and targets shape: (188,)\n",
      "Processing unit id: 7 with shape: (259, 26) and targets shape: (259,)\n",
      "Processing unit id: 8 with shape: (150, 26) and targets shape: (150,)\n",
      "Processing unit id: 9 with shape: (201, 26) and targets shape: (201,)\n",
      "Processing unit id: 10 with shape: (222, 26) and targets shape: (222,)\n",
      "Processing unit id: 11 with shape: (240, 26) and targets shape: (240,)\n",
      "Processing unit id: 12 with shape: (170, 26) and targets shape: (170,)\n",
      "Processing unit id: 13 with shape: (163, 26) and targets shape: (163,)\n",
      "Processing unit id: 14 with shape: (180, 26) and targets shape: (180,)\n",
      "Processing unit id: 15 with shape: (207, 26) and targets shape: (207,)\n",
      "Processing unit id: 16 with shape: (209, 26) and targets shape: (209,)\n",
      "Processing unit id: 17 with shape: (276, 26) and targets shape: (276,)\n",
      "Processing unit id: 18 with shape: (195, 26) and targets shape: (195,)\n",
      "Processing unit id: 19 with shape: (158, 26) and targets shape: (158,)\n",
      "Processing unit id: 20 with shape: (234, 26) and targets shape: (234,)\n",
      "Processing unit id: 21 with shape: (195, 26) and targets shape: (195,)\n",
      "Processing unit id: 22 with shape: (202, 26) and targets shape: (202,)\n",
      "Processing unit id: 23 with shape: (168, 26) and targets shape: (168,)\n",
      "Processing unit id: 24 with shape: (147, 26) and targets shape: (147,)\n",
      "Processing unit id: 25 with shape: (230, 26) and targets shape: (230,)\n",
      "Processing unit id: 26 with shape: (199, 26) and targets shape: (199,)\n",
      "Processing unit id: 27 with shape: (156, 26) and targets shape: (156,)\n",
      "Processing unit id: 28 with shape: (165, 26) and targets shape: (165,)\n",
      "Processing unit id: 29 with shape: (163, 26) and targets shape: (163,)\n",
      "Processing unit id: 30 with shape: (194, 26) and targets shape: (194,)\n",
      "Processing unit id: 31 with shape: (234, 26) and targets shape: (234,)\n",
      "Processing unit id: 32 with shape: (191, 26) and targets shape: (191,)\n",
      "Processing unit id: 33 with shape: (200, 26) and targets shape: (200,)\n",
      "Processing unit id: 34 with shape: (195, 26) and targets shape: (195,)\n",
      "Processing unit id: 35 with shape: (181, 26) and targets shape: (181,)\n",
      "Processing unit id: 36 with shape: (158, 26) and targets shape: (158,)\n",
      "Processing unit id: 37 with shape: (170, 26) and targets shape: (170,)\n",
      "Processing unit id: 38 with shape: (194, 26) and targets shape: (194,)\n",
      "Processing unit id: 39 with shape: (128, 26) and targets shape: (128,)\n",
      "Processing unit id: 40 with shape: (188, 26) and targets shape: (188,)\n",
      "Processing unit id: 41 with shape: (216, 26) and targets shape: (216,)\n",
      "Processing unit id: 42 with shape: (196, 26) and targets shape: (196,)\n",
      "Processing unit id: 43 with shape: (207, 26) and targets shape: (207,)\n",
      "Processing unit id: 44 with shape: (192, 26) and targets shape: (192,)\n",
      "Processing unit id: 45 with shape: (158, 26) and targets shape: (158,)\n",
      "Processing unit id: 46 with shape: (256, 26) and targets shape: (256,)\n",
      "Processing unit id: 47 with shape: (214, 26) and targets shape: (214,)\n",
      "Processing unit id: 48 with shape: (231, 26) and targets shape: (231,)\n",
      "Processing unit id: 49 with shape: (215, 26) and targets shape: (215,)\n",
      "Processing unit id: 50 with shape: (198, 26) and targets shape: (198,)\n",
      "Processing unit id: 51 with shape: (213, 26) and targets shape: (213,)\n",
      "Processing unit id: 52 with shape: (213, 26) and targets shape: (213,)\n",
      "Processing unit id: 53 with shape: (195, 26) and targets shape: (195,)\n",
      "Processing unit id: 54 with shape: (257, 26) and targets shape: (257,)\n",
      "Processing unit id: 55 with shape: (193, 26) and targets shape: (193,)\n",
      "Processing unit id: 56 with shape: (275, 26) and targets shape: (275,)\n",
      "Processing unit id: 57 with shape: (137, 26) and targets shape: (137,)\n",
      "Processing unit id: 58 with shape: (147, 26) and targets shape: (147,)\n",
      "Processing unit id: 59 with shape: (231, 26) and targets shape: (231,)\n",
      "Processing unit id: 60 with shape: (172, 26) and targets shape: (172,)\n",
      "Processing unit id: 61 with shape: (185, 26) and targets shape: (185,)\n",
      "Processing unit id: 62 with shape: (180, 26) and targets shape: (180,)\n",
      "Processing unit id: 63 with shape: (174, 26) and targets shape: (174,)\n",
      "Processing unit id: 64 with shape: (283, 26) and targets shape: (283,)\n",
      "Processing unit id: 65 with shape: (153, 26) and targets shape: (153,)\n",
      "Processing unit id: 66 with shape: (202, 26) and targets shape: (202,)\n",
      "Processing unit id: 67 with shape: (313, 26) and targets shape: (313,)\n",
      "Processing unit id: 68 with shape: (199, 26) and targets shape: (199,)\n",
      "Processing unit id: 69 with shape: (362, 26) and targets shape: (362,)\n",
      "Processing unit id: 70 with shape: (137, 26) and targets shape: (137,)\n",
      "Processing unit id: 71 with shape: (208, 26) and targets shape: (208,)\n",
      "Processing unit id: 72 with shape: (213, 26) and targets shape: (213,)\n",
      "Processing unit id: 73 with shape: (213, 26) and targets shape: (213,)\n",
      "Processing unit id: 74 with shape: (166, 26) and targets shape: (166,)\n",
      "Processing unit id: 75 with shape: (229, 26) and targets shape: (229,)\n",
      "Processing unit id: 76 with shape: (210, 26) and targets shape: (210,)\n",
      "Processing unit id: 77 with shape: (154, 26) and targets shape: (154,)\n",
      "Processing unit id: 78 with shape: (231, 26) and targets shape: (231,)\n",
      "Processing unit id: 79 with shape: (199, 26) and targets shape: (199,)\n",
      "Processing unit id: 80 with shape: (185, 26) and targets shape: (185,)\n",
      "Processing unit id: 81 with shape: (240, 26) and targets shape: (240,)\n",
      "Processing unit id: 82 with shape: (214, 26) and targets shape: (214,)\n",
      "Processing unit id: 83 with shape: (293, 26) and targets shape: (293,)\n",
      "Processing unit id: 84 with shape: (267, 26) and targets shape: (267,)\n",
      "Processing unit id: 85 with shape: (188, 26) and targets shape: (188,)\n",
      "Processing unit id: 86 with shape: (278, 26) and targets shape: (278,)\n",
      "Processing unit id: 87 with shape: (178, 26) and targets shape: (178,)\n",
      "Processing unit id: 88 with shape: (213, 26) and targets shape: (213,)\n",
      "Processing unit id: 89 with shape: (217, 26) and targets shape: (217,)\n",
      "Processing unit id: 90 with shape: (154, 26) and targets shape: (154,)\n",
      "Processing unit id: 91 with shape: (135, 26) and targets shape: (135,)\n",
      "Processing unit id: 92 with shape: (341, 26) and targets shape: (341,)\n",
      "Processing unit id: 93 with shape: (155, 26) and targets shape: (155,)\n",
      "Processing unit id: 94 with shape: (258, 26) and targets shape: (258,)\n",
      "Processing unit id: 95 with shape: (283, 26) and targets shape: (283,)\n",
      "Processing unit id: 96 with shape: (336, 26) and targets shape: (336,)\n",
      "Processing unit id: 97 with shape: (202, 26) and targets shape: (202,)\n",
      "Processing unit id: 98 with shape: (156, 26) and targets shape: (156,)\n",
      "Processing unit id: 99 with shape: (185, 26) and targets shape: (185,)\n",
      "Processing unit id: 100 with shape: (200, 26) and targets shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for unit_id in train_ids:\n",
    "\n",
    "    subset = train_df_scaled[train_df_scaled['unit_nr'] == unit_id]\n",
    "    subset_targets = train_df_merged[train_df_merged['unit_nr'] == unit_id]['RUL'].values\n",
    "    print(\"Processing unit id:\", unit_id, \"with shape:\", subset.shape, \"and targets shape:\", subset_targets.shape)\n",
    "    \n",
    "    x,y =create_sequences(subset, subset_targets, seq_length=sequence_length)\n",
    "    x_list.append(x)\n",
    "    y_list.append(y)\n",
    "\n",
    "for unit_id in test_ids:\n",
    "\n",
    "    subset = train_df_scaled[train_df_scaled['unit_nr'] == unit_id]\n",
    "    subset_targets = train_df_merged[train_df_merged['unit_nr'] == unit_id]['RUL'].values\n",
    "    print(\"Processing unit id:\", unit_id, \"with shape:\", subset.shape, \"and targets shape:\", subset_targets.shape)\n",
    "    \n",
    "    x,y =create_sequences(subset, subset_targets, seq_length=sequence_length)\n",
    "    x_test_list.append(x)\n",
    "    y_test_list.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>81</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.212644</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.411380</td>\n",
       "      <td>0.411546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179792</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.610743</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16139</th>\n",
       "      <td>81</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.331589</td>\n",
       "      <td>0.432647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208639</td>\n",
       "      <td>0.509427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.622756</td>\n",
       "      <td>238</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16140</th>\n",
       "      <td>81</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403614</td>\n",
       "      <td>0.335295</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.489804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.644573</td>\n",
       "      <td>237</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16141</th>\n",
       "      <td>81</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361446</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.381668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227991</td>\n",
       "      <td>0.444017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.726871</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16142</th>\n",
       "      <td>81</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.424024</td>\n",
       "      <td>0.461344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.277799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.603286</td>\n",
       "      <td>235</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "16138       81      0.00000   0.212644   0.750000        0.0  0.0  0.250000   \n",
       "16139       81      0.00277   0.632184   0.666667        0.0  0.0  0.433735   \n",
       "16140       81      0.00554   0.471264   0.916667        0.0  0.0  0.403614   \n",
       "16141       81      0.00831   0.494253   0.500000        0.0  0.0  0.361446   \n",
       "16142       81      0.01108   0.637931   0.666667        0.0  0.0  0.662651   \n",
       "\n",
       "            s_3       s_4  s_5  ...      s_14      s_15  s_16      s_17  s_18  \\\n",
       "16138  0.411380  0.411546  0.0  ...  0.179792  0.464025   0.0  0.250000   0.0   \n",
       "16139  0.331589  0.432647  0.0  ...  0.208639  0.509427   0.0  0.333333   0.0   \n",
       "16140  0.335295  0.238859  0.0  ...  0.205439  0.489804   0.0  0.500000   0.0   \n",
       "16141  0.519948  0.381668  0.0  ...  0.227991  0.444017   0.0  0.333333   0.0   \n",
       "16142  0.424024  0.461344  0.0  ...  0.202652  0.277799   0.0  0.333333   0.0   \n",
       "\n",
       "       s_19      s_20      s_21  RUL  max_cycle  \n",
       "16138   0.0  0.565891  0.610743  239        240  \n",
       "16139   0.0  0.596899  0.622756  238        240  \n",
       "16140   0.0  0.697674  0.644573  237        240  \n",
       "16141   0.0  0.488372  0.726871  236        240  \n",
       "16142   0.0  0.697674  0.603286  235        240  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_X_train = train_df_scaled[train_df_scaled['unit_nr'].isin(train_ids)]\n",
    "filtered_X_test = train_df_scaled[train_df_scaled['unit_nr'].isin(test_ids)]\n",
    "\n",
    "filtered_Y_train = train_df_merged[train_df_merged['unit_nr'].isin(train_ids)]\n",
    "filtered_Y_test = train_df_merged[train_df_merged['unit_nr'].isin(test_ids)]\n",
    "\n",
    "filtered_Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3ed9cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df shape: (16138, 28)\n",
      "Test df shape: (4493, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "0        1      0.00000   0.459770   0.166667        0.0  0.0  0.183735   \n",
       "1        1      0.00277   0.609195   0.250000        0.0  0.0  0.283133   \n",
       "2        1      0.00554   0.252874   0.750000        0.0  0.0  0.343373   \n",
       "3        1      0.00831   0.540230   0.500000        0.0  0.0  0.343373   \n",
       "4        1      0.01108   0.390805   0.333333        0.0  0.0  0.349398   \n",
       "\n",
       "        s_3       s_4  s_5  ...      s_14      s_15  s_16      s_17  s_18  \\\n",
       "0  0.406802  0.309757  0.0  ...  0.199608  0.363986   0.0  0.333333   0.0   \n",
       "1  0.453019  0.352633  0.0  ...  0.162813  0.411312   0.0  0.333333   0.0   \n",
       "2  0.369523  0.370527  0.0  ...  0.171793  0.357445   0.0  0.166667   0.0   \n",
       "3  0.256159  0.331195  0.0  ...  0.174889  0.166603   0.0  0.333333   0.0   \n",
       "4  0.257467  0.404625  0.0  ...  0.174734  0.402078   0.0  0.416667   0.0   \n",
       "\n",
       "   s_19      s_20      s_21  RUL  max_cycle  \n",
       "0   0.0  0.713178  0.724662  191        192  \n",
       "1   0.0  0.666667  0.731014  190        192  \n",
       "2   0.0  0.627907  0.621375  189        192  \n",
       "3   0.0  0.573643  0.662386  188        192  \n",
       "4   0.0  0.589147  0.704502  187        192  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = scaled_data_df[scaled_data_df['unit_nr'].isin(train_ids)]\n",
    "test_df = scaled_data_df[scaled_data_df['unit_nr'].isin(test_ids)]\n",
    "print(\"Train df shape:\", train_df.shape)\n",
    "print(\"Test df shape:\", test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b1d4b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Input Shape: (12218, 50, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def create_sequences_vectorized(X, y, unit_ids, seq_length=50):\n",
    "    # 1. Create windows (Batch, Seq, Features)\n",
    "    X_windows = sliding_window_view(X, window_shape=seq_length, axis=0)\n",
    "    X_windows = X_windows.transpose(0, 2, 1) # (Batch, Seq, Features)\n",
    "    \n",
    "    # 2. Align Targets (End of window)\n",
    "    y_aligned = y[seq_length-1:]\n",
    "    \n",
    "    # 3. Create Mask (Ensure window doesn't cross units)\n",
    "    unit_ids_start = unit_ids[:-seq_length+1]\n",
    "    unit_ids_end   = unit_ids[seq_length-1:]\n",
    "    valid_mask = (unit_ids_start == unit_ids_end)\n",
    "    \n",
    "    return X_windows[valid_mask], y_aligned[valid_mask]\n",
    "\n",
    "# --- Usage ---\n",
    "\n",
    "# 1. Prepare arrays (Sorted)\n",
    "filtered_X_train = train_df.sort_values(['unit_nr', 'time_cycles'])\n",
    "filtered_Y_train = train_df.sort_values(['unit_nr', 'time_cycles'])\n",
    "filtered_X_test = test_df.sort_values(['unit_nr', 'time_cycles'])\n",
    "filtered_Y_test = test_df.sort_values(['unit_nr', 'time_cycles'])\n",
    "\n",
    "# 2. CRITICAL: Drop Target (RUL) and max_cycle from Inputs\n",
    "# We only want the 24 sensor/setting columns + time_cycle\n",
    "features_to_drop = ['unit_nr', 'RUL', 'max_cycle', \"s_1\", \"s_5\", \"s_10\", \"s_16\", \"s_18\", \"s_19\"]\n",
    "\n",
    "X_train_arr = filtered_X_train.drop(columns=features_to_drop).values\n",
    "y_train_arr = filtered_Y_train['RUL'].values \n",
    "train_units = filtered_X_train['unit_nr'].values\n",
    "\n",
    "X_test_arr = filtered_X_test.drop(columns=features_to_drop).values\n",
    "y_test_arr = filtered_Y_test['RUL'].values\n",
    "test_units = filtered_X_test['unit_nr'].values\n",
    "\n",
    "# 3. Create Sequences\n",
    "X_train_seq, y_train_seq = create_sequences_vectorized(X_train_arr, y_train_arr, train_units, 50)\n",
    "X_test_seq, y_test_seq = create_sequences_vectorized(X_test_arr, y_test_arr, test_units, 50)\n",
    "\n",
    "print(f\"Train Input Shape: {X_train_seq.shape}\") \n",
    "# Expected shape: (N, 50, 24) -> 24 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "77279596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.45977011, 0.16666667, 0.        , 0.18373494,\n",
       "        0.40680183, 0.30975692, 1.        , 0.72624799, 0.24242424,\n",
       "        0.109755  , 0.36904762, 0.63326226, 0.20588235, 0.1996078 ,\n",
       "        0.36398615, 0.33333333, 0.71317829, 0.7246617 ],\n",
       "       [0.00277008, 0.6091954 , 0.25      , 0.        , 0.28313253,\n",
       "        0.4530194 , 0.35263336, 1.        , 0.62801932, 0.21212121,\n",
       "        0.1002423 , 0.38095238, 0.76545842, 0.27941176, 0.1628135 ,\n",
       "        0.41131204, 0.33333333, 0.66666667, 0.73101353],\n",
       "       [0.00554017, 0.25287356, 0.75      , 0.        , 0.34337349,\n",
       "        0.36952256, 0.37052667, 1.        , 0.71014493, 0.27272727,\n",
       "        0.14004308, 0.25      , 0.79530917, 0.22058824, 0.17179275,\n",
       "        0.35744517, 0.16666667, 0.62790698, 0.62137531],\n",
       "       [0.00831025, 0.54022989, 0.5       , 0.        , 0.34337349,\n",
       "        0.25615871, 0.33119514, 1.        , 0.74074074, 0.31818182,\n",
       "        0.12451763, 0.16666667, 0.8891258 , 0.29411765, 0.17488905,\n",
       "        0.16660254, 0.33333333, 0.57364341, 0.66238608],\n",
       "       [0.01108033, 0.3908046 , 0.33333333, 0.        , 0.34939759,\n",
       "        0.25746675, 0.40462525, 1.        , 0.66827697, 0.24242424,\n",
       "        0.14995962, 0.25595238, 0.74626866, 0.23529412, 0.17473423,\n",
       "        0.40207772, 0.41666667, 0.58914729, 0.70450152],\n",
       "       [0.01385042, 0.25287356, 0.41666667, 0.        , 0.26807229,\n",
       "        0.29278395, 0.27211344, 1.        , 0.77616747, 0.18181818,\n",
       "        0.12541506, 0.18452381, 0.63752665, 0.22058824, 0.16983177,\n",
       "        0.33051174, 0.25      , 0.65116279, 0.65272024],\n",
       "       [0.0166205 , 0.55747126, 0.58333333, 0.        , 0.38253012,\n",
       "        0.46391977, 0.26198515, 1.        , 0.72302738, 0.18181818,\n",
       "        0.16781836, 0.30357143, 0.77398721, 0.22058824, 0.16709671,\n",
       "        0.27895344, 0.33333333, 0.74418605, 0.667219  ],\n",
       "       [0.01939058, 0.3045977 , 0.75      , 0.        , 0.40662651,\n",
       "        0.25986484, 0.3160027 , 1.        , 0.64412238, 0.15151515,\n",
       "        0.08556942, 0.23214286, 0.80597015, 0.22058824, 0.16064609,\n",
       "        0.31819931, 0.25      , 0.64341085, 0.57497929],\n",
       "       [0.02216066, 0.54597701, 0.58333333, 0.        , 0.27409639,\n",
       "        0.43470678, 0.2118501 , 1.        , 0.61835749, 0.22727273,\n",
       "        0.11096653, 0.26190476, 0.66098081, 0.25      , 0.13288265,\n",
       "        0.18430165, 0.33333333, 0.70542636, 0.70753935],\n",
       "       [0.02493075, 0.31034483, 0.58333333, 0.        , 0.15060241,\n",
       "        0.44037497, 0.30739365, 1.        , 0.60225443, 0.22727273,\n",
       "        0.13447905, 0.10714286, 0.66098081, 0.26470588, 0.15192486,\n",
       "        0.39899962, 0.41666667, 0.62790698, 0.79425573],\n",
       "       [0.02770083, 0.60344828, 0.25      , 0.        , 0.32228916,\n",
       "        0.23348594, 0.31043214, 1.        , 0.75523349, 0.22727273,\n",
       "        0.12510096, 0.17857143, 0.57782516, 0.19117647, 0.20972237,\n",
       "        0.41977684, 0.33333333, 0.62015504, 0.80709749],\n",
       "       [0.03047091, 0.59195402, 0.66666667, 0.        , 0.2560241 ,\n",
       "        0.26967517, 0.3021607 , 1.        , 0.75201288, 0.28787879,\n",
       "        0.12402405, 0.19642857, 0.66311301, 0.20588235, 0.17705646,\n",
       "        0.26510196, 0.25      , 0.71317829, 0.65147749],\n",
       "       [0.033241  , 0.3908046 , 0.83333333, 0.        , 0.56024096,\n",
       "        0.24307826, 0.31363943, 1.        , 0.57809984, 0.33333333,\n",
       "        0.11258189, 0.31547619, 0.67377399, 0.29411765, 0.14531943,\n",
       "        0.34744132, 0.41666667, 0.6124031 , 0.52678818],\n",
       "       [0.03601108, 0.55172414, 0.5       , 0.        , 0.34337349,\n",
       "        0.47765424, 0.28544902, 1.        , 0.74557166, 0.28787879,\n",
       "        0.11504981, 0.35119048, 0.63539446, 0.17647059, 0.17798534,\n",
       "        0.27510581, 0.41666667, 0.80620155, 0.67439934],\n",
       "       [0.03878116, 0.39655172, 0.25      , 0.        , 0.36746988,\n",
       "        0.27861347, 0.33558406, 1.        , 0.61030596, 0.31818182,\n",
       "        0.13681235, 0.26785714, 0.81236674, 0.29411765, 0.14253277,\n",
       "        0.3655252 , 0.25      , 0.65891473, 0.62938415],\n",
       "       [0.04155125, 0.53448276, 0.91666667, 0.        , 0.27710843,\n",
       "        0.36930456, 0.37559082, 1.        , 0.65861514, 0.22727273,\n",
       "        0.12388944, 0.23214286, 0.59701493, 0.27941176, 0.18665497,\n",
       "        0.26433244, 0.33333333, 0.64341085, 0.77437172],\n",
       "       [0.04432133, 0.51149425, 0.66666667, 0.        , 0.4126506 ,\n",
       "        0.30346632, 0.2987846 , 1.        , 0.63607085, 0.24242424,\n",
       "        0.14892758, 0.16071429, 0.68230277, 0.23529412, 0.19264114,\n",
       "        0.49749904, 0.33333333, 0.51937984, 0.60439105],\n",
       "       [0.04709141, 0.32183908, 0.41666667, 0.        , 0.4246988 ,\n",
       "        0.43601482, 0.23413234, 1.        , 0.70048309, 0.22727273,\n",
       "        0.12483173, 0.21428571, 0.65458422, 0.27941176, 0.16921251,\n",
       "        0.29973067, 0.33333333, 0.58139535, 0.69663076],\n",
       "       [0.0498615 , 0.68390805, 0.25      , 0.        , 0.1746988 ,\n",
       "        0.36014825, 0.3055368 , 1.        , 0.69726248, 0.21212121,\n",
       "        0.14475455, 0.32738095, 0.68230277, 0.22058824, 0.15063474,\n",
       "        0.41246633, 0.25      , 0.51162791, 0.62441315],\n",
       "       [0.05263158, 0.28735632, 0.58333333, 0.        , 0.55120482,\n",
       "        0.21953346, 0.38791357, 1.        , 0.79871176, 0.22727273,\n",
       "        0.10845374, 0.2202381 , 0.7206823 , 0.20588235, 0.15362783,\n",
       "        0.3697576 , 0.33333333, 0.68992248, 0.7288042 ],\n",
       "       [0.05540166, 0.43103448, 0.58333333, 0.        , 0.34939759,\n",
       "        0.32766514, 0.26806212, 1.        , 0.68115942, 0.31818182,\n",
       "        0.11854976, 0.17857143, 0.79530917, 0.29411765, 0.17586954,\n",
       "        0.3078107 , 0.33333333, 0.73643411, 0.57428887],\n",
       "       [0.05817175, 0.51149425, 0.5       , 0.        , 0.46987952,\n",
       "        0.47721823, 0.30925051, 1.        , 0.60869565, 0.21212121,\n",
       "        0.17715157, 0.23214286, 0.70575693, 0.22058824, 0.15724017,\n",
       "        0.30203925, 0.33333333, 0.60465116, 0.6697045 ],\n",
       "       [0.06094183, 0.6954023 , 0.25      , 0.        , 0.28012048,\n",
       "        0.37388271, 0.21100608, 1.        , 0.66505636, 0.22727273,\n",
       "        0.11015884, 0.23809524, 0.60341151, 0.25      , 0.14428734,\n",
       "        0.3813005 , 0.33333333, 0.62015504, 0.77602872],\n",
       "       [0.06371191, 0.44252874, 0.75      , 0.        , 0.35240964,\n",
       "        0.43143667, 0.27954085, 1.        , 0.58615137, 0.33333333,\n",
       "        0.0988513 , 0.35119048, 0.73347548, 0.22058824, 0.17514707,\n",
       "        0.24701808, 0.33333333, 0.66666667, 0.65644849],\n",
       "       [0.06648199, 0.63218391, 0.16666667, 0.        , 0.46987952,\n",
       "        0.50272509, 0.28933153, 1.        , 0.66827697, 0.18181818,\n",
       "        0.14551737, 0.30357143, 0.82515991, 0.20588235, 0.18923522,\n",
       "        0.25702193, 0.41666667, 0.62790698, 0.73819387],\n",
       "       [0.06925208, 0.5       , 0.66666667, 0.        , 0.28614458,\n",
       "        0.39328537, 0.23328832, 1.        , 0.68599034, 0.25757576,\n",
       "        0.11388316, 0.24404762, 0.76545842, 0.26470588, 0.16105893,\n",
       "        0.38899577, 0.5       , 0.55813953, 0.71900028],\n",
       "       [0.07202216, 0.43103448, 0.16666667, 0.        , 0.37048193,\n",
       "        0.4235884 , 0.33068872, 1.        , 0.67954911, 0.18181818,\n",
       "        0.11769721, 0.30952381, 0.70575693, 0.36764706, 0.17886263,\n",
       "        0.30665641, 0.41666667, 0.65891473, 0.76360122],\n",
       "       [0.07479224, 0.36206897, 0.91666667, 0.        , 0.34337349,\n",
       "        0.25724875, 0.28494261, 1.        , 0.77777778, 0.33333333,\n",
       "        0.126133  , 0.33333333, 0.82729211, 0.29411765, 0.14119104,\n",
       "        0.41323586, 0.16666667, 0.6744186 , 0.53838719],\n",
       "       [0.07756233, 0.56896552, 0.41666667, 0.        , 0.21084337,\n",
       "        0.30063222, 0.31634031, 1.        , 0.70853462, 0.22727273,\n",
       "        0.12895989, 0.23214286, 0.79317697, 0.26470588, 0.17091547,\n",
       "        0.36167757, 0.41666667, 0.6124031 , 0.64277824],\n",
       "       [0.08033241, 0.37356322, 0.5       , 0.        , 0.29819277,\n",
       "        0.49008066, 0.23345712, 1.        , 0.72785829, 0.25757576,\n",
       "        0.10719734, 0.32738095, 0.74626866, 0.17647059, 0.19568583,\n",
       "        0.31396691, 0.16666667, 0.70542636, 0.71361502],\n",
       "       [0.08310249, 0.58045977, 0.91666667, 0.        , 0.2439759 ,\n",
       "        0.28646174, 0.24729912, 1.        , 0.68921095, 0.27272727,\n",
       "        0.16624787, 0.33333333, 0.69509595, 0.26470588, 0.13076685,\n",
       "        0.32897268, 0.33333333, 0.62015504, 0.60908589],\n",
       "       [0.08587258, 0.52873563, 0.25      , 0.        , 0.3373494 ,\n",
       "        0.44342708, 0.3057056 , 1.        , 0.82286634, 0.21212121,\n",
       "        0.13120345, 0.23809524, 0.68869936, 0.27941176, 0.15357622,\n",
       "        0.34590227, 0.33333333, 0.68217054, 0.83637117],\n",
       "       [0.08864266, 0.25862069, 0.16666667, 0.        , 0.45180723,\n",
       "        0.37846087, 0.34064821, 1.        , 0.76650564, 0.21212121,\n",
       "        0.1139729 , 0.25595238, 0.68656716, 0.29411765, 0.17793374,\n",
       "        0.19392074, 0.33333333, 0.53488372, 0.63021265],\n",
       "       [0.09141274, 0.5862069 , 0.41666667, 0.        , 0.40060241,\n",
       "        0.22738173, 0.30773126, 1.        , 0.71658615, 0.1969697 ,\n",
       "        0.11096653, 0.36904762, 0.64179104, 0.30882353, 0.1376303 ,\n",
       "        0.42323971, 0.33333333, 0.51937984, 0.57304612],\n",
       "       [0.09418283, 0.51724138, 0.66666667, 0.        , 0.37048193,\n",
       "        0.41334205, 0.35027009, 1.        , 0.71658615, 0.21212121,\n",
       "        0.10782554, 0.27380952, 0.65245203, 0.19117647, 0.20760656,\n",
       "        0.45440554, 0.25      , 0.76744186, 0.72107153],\n",
       "       [0.09695291, 0.47701149, 0.33333333, 0.        , 0.40060241,\n",
       "        0.23283192, 0.39314652, 1.        , 0.75362319, 0.16666667,\n",
       "        0.10244099, 0.23809524, 0.77398721, 0.23529412, 0.16792239,\n",
       "        0.38360908, 0.33333333, 0.55813953, 0.74095554],\n",
       "       [0.09972299, 0.47701149, 0.5       , 0.        , 0.23493976,\n",
       "        0.17593198, 0.28106009, 1.        , 0.76972625, 0.25757576,\n",
       "        0.15126088, 0.26190476, 0.76759062, 0.23529412, 0.16518733,\n",
       "        0.34359369, 0.33333333, 0.65891473, 0.74703121],\n",
       "       [0.10249307, 0.39655172, 0.33333333, 0.        , 0.21686747,\n",
       "        0.40462176, 0.29118839, 1.        , 0.78099839, 0.27272727,\n",
       "        0.15049807, 0.25      , 0.79530917, 0.29411765, 0.18923522,\n",
       "        0.3497499 , 0.33333333, 0.71317829, 0.8044739 ],\n",
       "       [0.10526316, 0.32758621, 0.41666667, 0.        , 0.24096386,\n",
       "        0.26531502, 0.31127616, 1.        , 0.66344605, 0.18181818,\n",
       "        0.13474827, 0.16071429, 0.75479744, 0.25      , 0.16446486,\n",
       "        0.34282416, 0.33333333, 0.43410853, 0.65686275],\n",
       "       [0.10803324, 0.5       , 0.16666667, 0.        , 0.31024096,\n",
       "        0.24068018, 0.32950709, 1.        , 0.76006441, 0.24242424,\n",
       "        0.14022256, 0.28571429, 0.67164179, 0.19117647, 0.16043967,\n",
       "        0.2058484 , 0.33333333, 0.54263566, 0.66652858],\n",
       "       [0.11080332, 0.68965517, 0.83333333, 0.        , 0.35843373,\n",
       "        0.44190102, 0.35381499, 1.        , 0.62318841, 0.24242424,\n",
       "        0.12231894, 0.14285714, 0.7206823 , 0.22058824, 0.19682114,\n",
       "        0.43131974, 0.33333333, 0.76744186, 0.75973488],\n",
       "       [0.11357341, 0.52873563, 0.16666667, 0.        , 0.27409639,\n",
       "        0.2969261 , 0.3229237 , 1.        , 0.65861514, 0.27272727,\n",
       "        0.15853002, 0.38095238, 0.75479744, 0.25      , 0.1596656 ,\n",
       "        0.34166987, 0.33333333, 0.66666667, 0.663905  ],\n",
       "       [0.11634349, 0.34482759, 0.91666667, 0.        , 0.31024096,\n",
       "        0.44647918, 0.40175557, 1.        , 0.61674718, 0.1969697 ,\n",
       "        0.16220946, 0.2797619 , 0.86353945, 0.30882353, 0.1407782 ,\n",
       "        0.3151212 , 0.33333333, 0.65891473, 0.58077879],\n",
       "       [0.11911357, 0.49425287, 0.66666667, 0.        , 0.21686747,\n",
       "        0.34663179, 0.31988521, 1.        , 0.69243156, 0.21212121,\n",
       "        0.11280625, 0.35714286, 0.76972281, 0.17647059, 0.16260708,\n",
       "        0.36629473, 0.33333333, 0.71317829, 0.80240265],\n",
       "       [0.12188366, 0.42528736, 0.5       , 0.        , 0.39759036,\n",
       "        0.24809244, 0.28544902, 1.        , 0.64090177, 0.27272727,\n",
       "        0.17315804, 0.35714286, 0.64818763, 0.25      , 0.14640314,\n",
       "        0.32704886, 0.41666667, 0.50387597, 0.6905551 ],\n",
       "       [0.12465374, 0.51724138, 0.58333333, 0.        , 0.36746988,\n",
       "        0.37606279, 0.32106685, 1.        , 0.62962963, 0.24242424,\n",
       "        0.17342726, 0.20833333, 0.71002132, 0.29411765, 0.14846733,\n",
       "        0.28010773, 0.41666667, 0.6124031 , 0.66321458],\n",
       "       [0.12742382, 0.5       , 0.91666667, 0.        , 0.30120482,\n",
       "        0.20231088, 0.34841323, 1.        , 0.7294686 , 0.24242424,\n",
       "        0.13600467, 0.2202381 , 0.67164179, 0.25      , 0.13556611,\n",
       "        0.27856868, 0.33333333, 0.65891473, 0.81897266],\n",
       "       [0.13019391, 0.6091954 , 0.58333333, 0.        , 0.20481928,\n",
       "        0.38085895, 0.28544902, 1.        , 0.67149758, 0.27272727,\n",
       "        0.10558198, 0.32738095, 0.68656716, 0.26470588, 0.15507276,\n",
       "        0.43362832, 0.33333333, 0.62015504, 0.65009666],\n",
       "       [0.13296399, 0.41954023, 0.91666667, 0.        , 0.30722892,\n",
       "        0.29016787, 0.26181634, 1.        , 0.70531401, 0.25757576,\n",
       "        0.1297227 , 0.2202381 , 0.57142857, 0.23529412, 0.18340386,\n",
       "        0.34705656, 0.33333333, 0.71317829, 0.76719138],\n",
       "       [0.13573407, 0.31609195, 0.41666667, 0.        , 0.46987952,\n",
       "        0.38042293, 0.36073599, 1.        , 0.65539452, 0.24242424,\n",
       "        0.12056897, 0.36904762, 0.7761194 , 0.30882353, 0.14119104,\n",
       "        0.33358984, 0.33333333, 0.5503876 , 0.71306269]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0f61638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([12218, 50, 19])\n",
      "y_train_tensor.shape: torch.Size([12218])\n",
      "X_test_tensor.shape: torch.Size([3513, 50, 19])\n",
      "y_test_tensor.shape: torch.Size([3513])\n",
      "X_test_tensor[0]: tensor([[0.0000, 0.2126, 0.7500, 0.0000, 0.2500, 0.4114, 0.4115, 1.0000, 0.6329,\n",
      "         0.3030, 0.1739, 0.4048, 0.7249, 0.2353, 0.1798, 0.4640, 0.2500, 0.5659,\n",
      "         0.6107],\n",
      "        [0.0028, 0.6322, 0.6667, 0.0000, 0.4337, 0.3316, 0.4326, 1.0000, 0.6200,\n",
      "         0.2879, 0.1911, 0.3214, 0.7207, 0.2794, 0.2086, 0.5094, 0.3333, 0.5969,\n",
      "         0.6228],\n",
      "        [0.0055, 0.4713, 0.9167, 0.0000, 0.4036, 0.3353, 0.2389, 1.0000, 0.5523,\n",
      "         0.3182, 0.1657, 0.3214, 0.5075, 0.2647, 0.2054, 0.4898, 0.5000, 0.6977,\n",
      "         0.6446],\n",
      "        [0.0083, 0.4943, 0.5000, 0.0000, 0.3614, 0.5199, 0.3817, 1.0000, 0.7085,\n",
      "         0.2121, 0.1562, 0.4405, 0.6375, 0.2353, 0.2280, 0.4440, 0.3333, 0.4884,\n",
      "         0.7269],\n",
      "        [0.0111, 0.6379, 0.6667, 0.0000, 0.6627, 0.4240, 0.4613, 1.0000, 0.5878,\n",
      "         0.2121, 0.1649, 0.2321, 0.5928, 0.3529, 0.2027, 0.2778, 0.3333, 0.6977,\n",
      "         0.6033],\n",
      "        [0.0139, 0.5287, 0.3333, 0.0000, 0.4639, 0.4027, 0.5464, 1.0000, 0.6023,\n",
      "         0.2273, 0.1508, 0.3095, 0.5736, 0.2353, 0.2218, 0.3355, 0.2500, 0.6124,\n",
      "         0.7363],\n",
      "        [0.0166, 0.5747, 0.2500, 0.0000, 0.3886, 0.3671, 0.3364, 1.0000, 0.7037,\n",
      "         0.1515, 0.1596, 0.5179, 0.6290, 0.2500, 0.1830, 0.4652, 0.2500, 0.5814,\n",
      "         0.5851],\n",
      "        [0.0194, 0.5690, 0.3333, 0.0000, 0.3404, 0.4700, 0.3378, 1.0000, 0.6683,\n",
      "         0.2576, 0.1626, 0.1667, 0.7484, 0.2794, 0.2125, 0.2801, 0.3333, 0.5504,\n",
      "         0.7081],\n",
      "        [0.0222, 0.7356, 0.4167, 0.0000, 0.4669, 0.2418, 0.1573, 1.0000, 0.6683,\n",
      "         0.1970, 0.1649, 0.3393, 0.5842, 0.2794, 0.2412, 0.3355, 0.2500, 0.7364,\n",
      "         0.6261],\n",
      "        [0.0249, 0.4655, 0.7500, 0.0000, 0.2319, 0.4875, 0.4468, 1.0000, 0.6329,\n",
      "         0.3182, 0.1462, 0.3571, 0.6695, 0.2353, 0.1998, 0.4937, 0.5000, 0.5271,\n",
      "         0.6798],\n",
      "        [0.0277, 0.4828, 0.1667, 0.0000, 0.3916, 0.2974, 0.1948, 1.0000, 0.6844,\n",
      "         0.1970, 0.1585, 0.4048, 0.6802, 0.2794, 0.2031, 0.4267, 0.2500, 0.4884,\n",
      "         0.6066],\n",
      "        [0.0305, 0.4483, 0.8333, 0.0000, 0.4940, 0.3547, 0.4247, 1.0000, 0.5475,\n",
      "         0.3030, 0.1684, 0.3750, 0.7058, 0.2794, 0.1731, 0.3740, 0.4167, 0.7054,\n",
      "         0.5747],\n",
      "        [0.0332, 0.6379, 0.6667, 0.0000, 0.3976, 0.2899, 0.3371, 1.0000, 0.7230,\n",
      "         0.2727, 0.1728, 0.3274, 0.7463, 0.3088, 0.2203, 0.3236, 0.4167, 0.6047,\n",
      "         0.4943],\n",
      "        [0.0360, 0.7701, 0.5833, 0.0000, 0.1476, 0.3316, 0.3045, 1.0000, 0.6135,\n",
      "         0.2576, 0.1688, 0.3869, 0.6759, 0.2794, 0.2000, 0.4252, 0.3333, 0.6357,\n",
      "         0.6471],\n",
      "        [0.0388, 0.3621, 0.8333, 0.0000, 0.4187, 0.3054, 0.2900, 1.0000, 0.7166,\n",
      "         0.2879, 0.1831, 0.3869, 0.6674, 0.2353, 0.2258, 0.2586, 0.4167, 0.5116,\n",
      "         0.7531],\n",
      "        [0.0416, 0.5862, 0.4167, 0.0000, 0.4337, 0.3455, 0.4283, 1.0000, 0.5765,\n",
      "         0.1818, 0.1743, 0.2619, 0.6205, 0.2941, 0.2127, 0.3397, 0.3333, 0.6899,\n",
      "         0.6882],\n",
      "        [0.0443, 0.6264, 0.2500, 0.0000, 0.3645, 0.3793, 0.3727, 1.0000, 0.5926,\n",
      "         0.3030, 0.1896, 0.3214, 0.5672, 0.2647, 0.2104, 0.6691, 0.3333, 0.6357,\n",
      "         0.6435],\n",
      "        [0.0471, 0.5862, 0.6667, 0.0000, 0.5151, 0.3242, 0.3341, 1.0000, 0.5894,\n",
      "         0.2727, 0.1545, 0.3274, 0.6631, 0.3235, 0.1862, 0.3863, 0.3333, 0.5271,\n",
      "         0.6772],\n",
      "        [0.0499, 0.4138, 0.8333, 0.0000, 0.3223, 0.3283, 0.4018, 1.0000, 0.6634,\n",
      "         0.3030, 0.1371, 0.3631, 0.6887, 0.2941, 0.2172, 0.3617, 0.4167, 0.6434,\n",
      "         0.5098],\n",
      "        [0.0526, 0.4943, 0.5000, 0.0000, 0.4217, 0.3926, 0.2716, 1.0000, 0.5620,\n",
      "         0.1818, 0.1689, 0.3690, 0.7207, 0.3235, 0.2015, 0.3728, 0.4167, 0.5271,\n",
      "         0.6721],\n",
      "        [0.0554, 0.5575, 0.2500, 0.0000, 0.4699, 0.4027, 0.4580, 1.0000, 0.6731,\n",
      "         0.2727, 0.2028, 0.3571, 0.6866, 0.2353, 0.2163, 0.3678, 0.3333, 0.5814,\n",
      "         0.7277],\n",
      "        [0.0582, 0.5230, 0.5000, 0.0000, 0.3554, 0.2889, 0.4056, 1.0000, 0.7407,\n",
      "         0.2576, 0.2023, 0.4524, 0.6588, 0.2647, 0.2068, 0.3182, 0.4167, 0.6822,\n",
      "         0.5229],\n",
      "        [0.0609, 0.6552, 0.8333, 0.0000, 0.5361, 0.2538, 0.3396, 1.0000, 0.7568,\n",
      "         0.2879, 0.1771, 0.3155, 0.7484, 0.2647, 0.2119, 0.3736, 0.5000, 0.6047,\n",
      "         0.6479],\n",
      "        [0.0637, 0.3391, 0.3333, 0.0000, 0.2590, 0.4408, 0.3261, 1.0000, 0.6957,\n",
      "         0.2121, 0.1917, 0.3512, 0.6503, 0.3235, 0.1848, 0.4817, 0.3333, 0.5969,\n",
      "         0.7154],\n",
      "        [0.0665, 0.7184, 0.7500, 0.0000, 0.4217, 0.4822, 0.3839, 1.0000, 0.5507,\n",
      "         0.3182, 0.1435, 0.3036, 0.6844, 0.2353, 0.2052, 0.3363, 0.4167, 0.5504,\n",
      "         0.5222],\n",
      "        [0.0693, 0.4770, 0.9167, 0.0000, 0.2861, 0.4317, 0.4002, 1.0000, 0.7101,\n",
      "         0.1515, 0.1515, 0.3690, 0.6631, 0.2794, 0.1978, 0.2532, 0.3333, 0.4806,\n",
      "         0.4392],\n",
      "        [0.0720, 0.6149, 0.1667, 0.0000, 0.3886, 0.1591, 0.4477, 1.0000, 0.6151,\n",
      "         0.2273, 0.1640, 0.2976, 0.7036, 0.1912, 0.1975, 0.4186, 0.3333, 0.5271,\n",
      "         0.6433],\n",
      "        [0.0748, 0.4080, 0.8333, 0.0000, 0.3976, 0.2797, 0.4129, 1.0000, 0.6602,\n",
      "         0.2879, 0.1750, 0.3333, 0.6567, 0.2353, 0.2280, 0.4179, 0.5000, 0.5891,\n",
      "         0.5148],\n",
      "        [0.0776, 0.6379, 0.5833, 0.0000, 0.3614, 0.5097, 0.4301, 1.0000, 0.5894,\n",
      "         0.2576, 0.1836, 0.3631, 0.6461, 0.3235, 0.2048, 0.2447, 0.5000, 0.5194,\n",
      "         0.6134],\n",
      "        [0.0803, 0.4483, 0.8333, 0.0000, 0.4608, 0.3043, 0.4752, 1.0000, 0.6039,\n",
      "         0.1515, 0.1478, 0.3869, 0.5842, 0.2647, 0.2275, 0.3371, 0.2500, 0.6667,\n",
      "         0.6904],\n",
      "        [0.0831, 0.5575, 0.4167, 0.0000, 0.3916, 0.3104, 0.3307, 1.0000, 0.5250,\n",
      "         0.2727, 0.1877, 0.3095, 0.7122, 0.3235, 0.2063, 0.1958, 0.4167, 0.5426,\n",
      "         0.5267],\n",
      "        [0.0859, 0.4713, 0.7500, 0.0000, 0.4578, 0.2884, 0.3596, 1.0000, 0.5684,\n",
      "         0.2576, 0.1566, 0.2976, 0.6183, 0.2794, 0.2249, 0.4344, 0.4167, 0.5271,\n",
      "         0.5106],\n",
      "        [0.0886, 0.4483, 0.4167, 0.0000, 0.3645, 0.3776, 0.3212, 1.0000, 0.6699,\n",
      "         0.2727, 0.1802, 0.3929, 0.7271, 0.3235, 0.2098, 0.5448, 0.4167, 0.6822,\n",
      "         0.4649],\n",
      "        [0.0914, 0.3908, 0.5833, 0.0000, 0.3916, 0.5675, 0.4507, 1.0000, 0.5942,\n",
      "         0.3182, 0.1625, 0.2976, 0.7399, 0.2500, 0.2169, 0.3305, 0.3333, 0.4806,\n",
      "         0.5650],\n",
      "        [0.0942, 0.3161, 0.6667, 0.0000, 0.5452, 0.3710, 0.4332, 1.0000, 0.5459,\n",
      "         0.3030, 0.2066, 0.1964, 0.7292, 0.2794, 0.1975, 0.3932, 0.3333, 0.6899,\n",
      "         0.7231],\n",
      "        [0.0970, 0.3908, 0.4167, 0.0000, 0.3012, 0.3026, 0.2593, 1.0000, 0.5700,\n",
      "         0.2121, 0.1531, 0.3571, 0.5522, 0.2941, 0.2108, 0.3463, 0.4167, 0.5271,\n",
      "         0.6001],\n",
      "        [0.0997, 0.5690, 0.9167, 0.0000, 0.3163, 0.2575, 0.3545, 1.0000, 0.6393,\n",
      "         0.2879, 0.1570, 0.3214, 0.5864, 0.3088, 0.2021, 0.4059, 0.3333, 0.5814,\n",
      "         0.7241],\n",
      "        [0.1025, 0.4425, 0.6667, 0.0000, 0.2982, 0.3780, 0.4419, 1.0000, 0.6715,\n",
      "         0.1970, 0.1829, 0.3631, 0.6567, 0.2941, 0.2439, 0.2389, 0.2500, 0.4884,\n",
      "         0.5291],\n",
      "        [0.1053, 0.5000, 0.1667, 0.0000, 0.4578, 0.4879, 0.3958, 1.0000, 0.6119,\n",
      "         0.2576, 0.1450, 0.3571, 0.6759, 0.2941, 0.2039, 0.3447, 0.1667, 0.5659,\n",
      "         0.4923],\n",
      "        [0.1080, 0.4138, 0.5000, 0.0000, 0.2741, 0.3643, 0.4262, 1.0000, 0.7085,\n",
      "         0.2879, 0.1763, 0.3333, 0.7015, 0.2647, 0.2282, 0.3855, 0.4167, 0.5814,\n",
      "         0.7450],\n",
      "        [0.1108, 0.4080, 0.9167, 0.0000, 0.4578, 0.1365, 0.3327, 1.0000, 0.5878,\n",
      "         0.2576, 0.1976, 0.2798, 0.7825, 0.2941, 0.2303, 0.4756, 0.5833, 0.5891,\n",
      "         0.6693],\n",
      "        [0.1136, 0.5977, 0.3333, 0.0000, 0.4729, 0.3017, 0.3982, 1.0000, 0.6135,\n",
      "         0.1667, 0.1344, 0.3571, 0.5650, 0.2353, 0.2195, 0.4359, 0.4167, 0.7209,\n",
      "         0.6106],\n",
      "        [0.1163, 0.6897, 0.9167, 0.0000, 0.3675, 0.4637, 0.4173, 1.0000, 0.6989,\n",
      "         0.1818, 0.1693, 0.3393, 0.7186, 0.2500, 0.2005, 0.4182, 0.5000, 0.4806,\n",
      "         0.5606],\n",
      "        [0.1191, 0.5690, 0.1667, 0.0000, 0.4217, 0.4186, 0.4740, 1.0000, 0.5926,\n",
      "         0.2576, 0.1694, 0.4167, 0.6077, 0.2941, 0.1800, 0.4017, 0.4167, 0.6047,\n",
      "         0.5576],\n",
      "        [0.1219, 0.3046, 0.1667, 0.0000, 0.5693, 0.1836, 0.2880, 1.0000, 0.7166,\n",
      "         0.2424, 0.1487, 0.3690, 0.6333, 0.2941, 0.2095, 0.4240, 0.4167, 0.6202,\n",
      "         0.5267],\n",
      "        [0.1247, 0.6609, 0.9167, 0.0000, 0.4187, 0.4138, 0.3494, 1.0000, 0.5604,\n",
      "         0.1818, 0.1751, 0.2560, 0.6866, 0.3529, 0.2146, 0.3247, 0.5000, 0.5969,\n",
      "         0.5526],\n",
      "        [0.1274, 0.5345, 0.2500, 0.0000, 0.3584, 0.4750, 0.3540, 1.0000, 0.6876,\n",
      "         0.2121, 0.1441, 0.3810, 0.5458, 0.3971, 0.2161, 0.4817, 0.3333, 0.5426,\n",
      "         0.6640],\n",
      "        [0.1302, 0.5345, 0.1667, 0.0000, 0.3313, 0.4205, 0.3300, 1.0000, 0.6103,\n",
      "         0.1818, 0.1677, 0.3274, 0.7335, 0.2647, 0.2032, 0.3324, 0.4167, 0.5426,\n",
      "         0.5427],\n",
      "        [0.1330, 0.4023, 0.9167, 0.0000, 0.3223, 0.4105, 0.3754, 1.0000, 0.7069,\n",
      "         0.2879, 0.1906, 0.3690, 0.5885, 0.2794, 0.2082, 0.4960, 0.4167, 0.6434,\n",
      "         0.7490],\n",
      "        [0.1357, 0.5517, 0.9167, 0.0000, 0.1747, 0.4596, 0.3506, 1.0000, 0.6184,\n",
      "         0.3030, 0.1780, 0.2738, 0.6844, 0.2353, 0.2328, 0.1893, 0.3333, 0.6977,\n",
      "         0.6346]])\n",
      "y_test_tensor[0]: 190.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.float32)   \n",
    "\n",
    "print(f\"X_train_tensor.shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor.shape: {y_train_tensor.shape}\")\n",
    "\n",
    "print(f\"X_test_tensor.shape: {X_test_tensor.shape}\")\n",
    "print(f\"y_test_tensor.shape: {y_test_tensor.shape}\")\n",
    "print(f\"X_test_tensor[0]: {X_test_tensor[0]}\")\n",
    "print(f\"y_test_tensor[0]: {y_test_tensor[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bdb94636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EngineRULPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        last_out = out[:, -1, :]\n",
    "        \n",
    "        # Pass it through the linear layer\n",
    "        final_prediction = self.fc(last_out)\n",
    "        return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8d83b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/300, Loss: 0.093817\n",
      "Epoch 11/300, Loss: 0.033890\n",
      "Epoch 21/300, Loss: 0.027514\n",
      "Epoch 31/300, Loss: 0.015324\n",
      "Epoch 41/300, Loss: 0.012839\n",
      "Epoch 51/300, Loss: 0.012032\n",
      "Epoch 61/300, Loss: 0.011803\n",
      "Epoch 71/300, Loss: 0.011571\n",
      "Epoch 81/300, Loss: 0.011380\n",
      "Epoch 91/300, Loss: 0.011284\n",
      "Epoch 101/300, Loss: 0.011142\n",
      "Epoch 111/300, Loss: 0.011101\n",
      "Epoch 121/300, Loss: 0.011010\n",
      "Epoch 131/300, Loss: 0.010970\n",
      "Epoch 141/300, Loss: 0.010929\n",
      "Epoch 151/300, Loss: 0.010905\n",
      "Epoch 161/300, Loss: 0.010840\n",
      "Epoch 171/300, Loss: 0.010815\n",
      "Epoch 181/300, Loss: 0.010773\n",
      "Epoch 191/300, Loss: 0.010738\n",
      "Epoch 201/300, Loss: 0.010730\n",
      "Epoch 211/300, Loss: 0.010781\n",
      "Epoch 221/300, Loss: 0.010689\n",
      "Epoch 231/300, Loss: 0.010653\n",
      "Epoch 241/300, Loss: 0.010640\n",
      "Epoch 251/300, Loss: 0.010670\n",
      "Epoch 261/300, Loss: 0.010679\n",
      "Epoch 271/300, Loss: 0.010674\n",
      "Epoch 281/300, Loss: 0.010624\n",
      "Epoch 291/300, Loss: 0.010586\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 1. Scale Targets to 0-1 range (Max RUL is approx 300)\n",
    "max_rul = 300.0 \n",
    "y_train_scaled = y_train_seq / max_rul\n",
    "\n",
    "# 2. Convert to Tensors\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "model = EngineRULPredictor(input_size=X_train_tensor.shape[2], hidden_size=100)\n",
    "\n",
    "model = model.to(device) # Move model to GPU\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "EPOCHS = 300\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train_tensor)\n",
    "    \n",
    "    # Loss is calculated on SCALED targets (0-1)\n",
    "    loss = criterion(out.squeeze(), y_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "869a15e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Mini-Batch Training...\n",
      "Epoch 10/300, Avg Loss: 0.007468\n",
      "Epoch 20/300, Avg Loss: 0.004993\n",
      "Epoch 30/300, Avg Loss: 0.003700\n",
      "Epoch 40/300, Avg Loss: 0.002751\n",
      "Epoch 50/300, Avg Loss: 0.001665\n",
      "Epoch 60/300, Avg Loss: 0.001458\n",
      "Epoch 70/300, Avg Loss: 0.000867\n",
      "Epoch 80/300, Avg Loss: 0.000352\n",
      "Epoch 90/300, Avg Loss: 0.000498\n",
      "Epoch 100/300, Avg Loss: 0.000195\n",
      "Epoch 110/300, Avg Loss: 0.000108\n",
      "Epoch 120/300, Avg Loss: 0.001040\n",
      "Epoch 130/300, Avg Loss: 0.000083\n",
      "Epoch 140/300, Avg Loss: 0.000065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[297]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m loss = criterion(out.squeeze(), y_batch)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m optimizer.step()\n\u001b[32m     41\u001b[39m epoch_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/gemini-lstm-next-frame-prediction/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/gemini-lstm-next-frame-prediction/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/gemini-lstm-next-frame-prediction/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
    "# 1. Create a DataLoader (This enables Mini-Batching)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Update Model (Make it slightly larger for better accuracy)\n",
    "model = EngineRULPredictor(input_size=X_train_tensor.shape[2], hidden_size=256, num_layers=2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. Fix Scheduler (Decay less aggressively)\n",
    "# Decay by 10% every 100 epochs instead of 50% every 50 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.9)\n",
    "\n",
    "EPOCHS = 300 # You likely need fewer epochs with mini-batching\n",
    "\n",
    "model.train()\n",
    "print(\"Starting Mini-Batch Training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Iterate through batches\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (Batch only)\n",
    "        out = model(X_batch)\n",
    "        loss = criterion(out.squeeze(), y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Step scheduler once per epoch\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Avg Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b0ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with Validation...\n",
      "Epoch 1: New Best RMSE: 48.13\n",
      "Epoch 2: New Best RMSE: 46.70\n",
      "Epoch 3: New Best RMSE: 44.40\n",
      "Epoch 4: New Best RMSE: 39.80\n",
      "Epoch 6: New Best RMSE: 35.79\n",
      "Epoch 7: New Best RMSE: 34.02\n",
      "Epoch 8: New Best RMSE: 31.41\n",
      "Epoch 9: New Best RMSE: 28.71\n",
      "Epoch 10: Train Loss 0.005744 | Test RMSE 38.32\n",
      "Epoch 20: Train Loss 0.005049 | Test RMSE 30.94\n",
      "Epoch 30: Train Loss 0.004031 | Test RMSE 33.93\n",
      "Epoch 40: Train Loss 0.003714 | Test RMSE 32.96\n",
      "Epoch 50: Train Loss 0.002417 | Test RMSE 34.68\n",
      "Epoch 60: Train Loss 0.001994 | Test RMSE 33.83\n",
      "Epoch 70: Train Loss 0.004916 | Test RMSE 30.56\n",
      "Epoch 80: Train Loss 0.001138 | Test RMSE 34.76\n",
      "Epoch 90: Train Loss 0.002672 | Test RMSE 30.59\n",
      "Epoch 100: Train Loss 0.000897 | Test RMSE 34.46\n",
      "Epoch 110: Train Loss 0.002160 | Test RMSE 34.55\n",
      "Epoch 120: Train Loss 0.000587 | Test RMSE 36.05\n",
      "Epoch 130: Train Loss 0.000423 | Test RMSE 37.75\n",
      "Epoch 140: Train Loss 0.002002 | Test RMSE 31.48\n",
      "Epoch 150: Train Loss 0.001286 | Test RMSE 29.89\n",
      "Training complete. Best RMSE: 28.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# 1. Add Dropout to the Model\n",
    "class EngineRULPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        # Dropout only works if num_layers > 1\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        return self.fc(last_out)\n",
    "\n",
    "# 2. Setup (Reduced hidden size slightly to 128 to prevent overfitting)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EngineRULPredictor(input_size=X_train_tensor.shape[2], hidden_size=128, num_layers=2, dropout=0.3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# 3. Training with \"Save Best\" logic\n",
    "EPOCHS = 150  # Lower epochs, let early stopping do the work\n",
    "best_test_rmse = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Move validation data to GPU once\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "y_test_real = y_test_seq # Keep real values for RMSE calculation\n",
    "\n",
    "print(\"Starting Training with Validation...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() # Set to training mode (enables Dropout)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_batch)\n",
    "        loss = criterion(out.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # --- Validation Step ---\n",
    "    model.eval() # Set to eval mode (disables Dropout)\n",
    "    with torch.no_grad():\n",
    "        # Get predictions\n",
    "        preds_scaled = model(X_test_gpu).cpu().numpy().flatten()\n",
    "        # Unscale\n",
    "        preds_real = preds_scaled * max_rul\n",
    "        # Calculate true RMSE\n",
    "        mse = mean_squared_error(y_test_real, preds_real)\n",
    "        current_rmse = np.sqrt(mse)\n",
    "        scheduler.step(current_rmse)\n",
    "    \n",
    "    # Save model if it's the best so far\n",
    "    if current_rmse < best_test_rmse:\n",
    "        best_test_rmse = current_rmse\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Epoch {epoch+1}: New Best RMSE: {current_rmse:.2f}\")\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss {avg_train_loss:.6f} | Test RMSE {current_rmse:.2f}\")\n",
    "\n",
    "# 4. Load the best weights back\n",
    "print(f\"Training complete. Best RMSE: {best_test_rmse:.2f}\")\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4f26dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 28.85\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_tensor = X_test_tensor.to(\"cpu\")\n",
    "y_test_tensor = y_test_tensor.to(\"cpu\")\n",
    "model.to(\"cpu\")\n",
    "\n",
    "#X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
    "# y_test_seq is the original TRUE RUL (not scaled)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predict (Output is 0-1)\n",
    "    preds_scaled = model(X_test_tensor)\n",
    "    # Un-scale (Output becomes 0-300)\n",
    "    preds_real = preds_scaled.cpu().numpy().flatten() * max_rul\n",
    "\n",
    "# Calculate RMSE on real values\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test_seq, preds_real)\n",
    "print(f\"Test RMSE: {np.sqrt(mse):.2f}\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_test_seq[:200], label='True RUL')\n",
    "plt.plot(preds_real[:200], label='Predicted RUL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e8a2a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Active device: NVIDIA GeForce RTX 5060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'CUDA device count: {torch.cuda.device_count()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Active device: {torch.cuda.get_device_name(torch.cuda.current_device())}')\n",
    "else:\n",
    "    print('No CUDA devices detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e30748f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result tensor device: cuda:0\n",
      "Result sample: 3.887904\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemExit('CUDA is not available; skipping tensor test.')\n",
    "device = torch.device('cuda')\n",
    "x = torch.randn(1000, 1000, device=device)\n",
    "y = torch.randn(1000, 1000, device=device)\n",
    "z = torch.matmul(x, y)\n",
    "print(f'Result tensor device: {z.device}')\n",
    "print(f'Result sample: {z.flatten()[0].item():.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-lstm-next-frame-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
